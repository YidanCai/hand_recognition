{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V1_0_hand_homework 4th.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDOc4QOTSwkG"
      },
      "source": [
        "Run all the cells in order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFbRVUD2xOHg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7ddb4c00-d609-4b9d-c4a0-5f58e80a3fe8"
      },
      "source": [
        "#mount the google driver\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epvKVMfbkOF4"
      },
      "source": [
        "#import dependencies\n",
        "from IPython.display import display, Javascript,HTML, JSON\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "from PIL import Image\n",
        "import io\n",
        "import numpy as np\n",
        "import cv2 \n",
        "import os\n",
        "import IPython\n",
        "import uuid\n",
        "from google.colab import output\n",
        "from IPython.display import Image as Im\n",
        "import time, sys\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRNs-YIGSRSl"
      },
      "source": [
        "we need to get the haarcascade file for using use Casscasde Classifier in the fact detect part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePo8QbnmkGzJ"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt.xml -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4csliqI60tS"
      },
      "source": [
        "#save the cascade file, we'll use it later\n",
        "cascade_fn = \"haarcascade_frontalface_alt.xml\"\n",
        "cascade = cv2.CascadeClassifier(cv2.samples.findFile(cascade_fn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTgtwxyGCgui"
      },
      "source": [
        "#define functions\n",
        "#use array to represent the image\n",
        "def byte2image(byte):\n",
        "  jpeg = b64decode(byte.split(',')[1])\n",
        "  im = Image.open(io.BytesIO(jpeg))\n",
        "  return np.array(im)\n",
        "\n",
        "# encode from array to b64 code\n",
        "def image2byte(image):\n",
        "  image = Image.fromarray(image)\n",
        "  buffer = io.BytesIO()\n",
        "  image.save(buffer, 'jpeg')\n",
        "  buffer.seek(0)\n",
        "  x = b64encode(buffer.read()).decode('utf-8')\n",
        "  return x\n",
        "\n",
        "#this function draws the square\n",
        "def draw_rects(img, rect, color):\n",
        "    x1, y1, x2, y2 = rect\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), color, 8)\n",
        "\n",
        "#this function detect the face in image and return the position\n",
        "def detect(img, cascade):\n",
        "  #Apply the AdaBoost classifier \n",
        "    rects = cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=4, minSize=(30, 30),\n",
        "                                     flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "    if len(rects) == 0:\n",
        "        return []\n",
        "   #If faces are found, it returns the positions of detected faces as Rect(x,y,w,h),we then transfer it to (x,y,x+w,y+h)\n",
        "    rects[:,2:] += rects[:,:2]\n",
        "    return rects\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-3hWVE4S7uF"
      },
      "source": [
        "This function is for showing video and taking photo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_WzLBI4kQCI"
      },
      "source": [
        "def VideoCapture():\n",
        "  js = Javascript('''\n",
        "    async function create(){\n",
        "      div = document.createElement('div');\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.style.display = \"none\";\n",
        "\n",
        "      div.appendChild(video);\n",
        "\n",
        "      stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: \"environment\"}});\n",
        "      video.srcObject = stream;\n",
        "\n",
        "      await video.play();\n",
        "\n",
        "      canvas =  document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "      div_out = document.createElement('div');\n",
        "      document.body.appendChild(div_out);\n",
        "      \n",
        "      img224 = document.createElement('img');\n",
        "      img224.id = \"finalImage224\";\n",
        "      div_out.appendChild(img224);\n",
        "\n",
        "      img64 = document.createElement('img');\n",
        "      img64.id = \"finalImage64\";\n",
        "      div_out.appendChild(img64);\n",
        "\n",
        "      transfer = document.createElement('div');\n",
        "      transfer.id = \"transfer\";\n",
        "      transfer.style.color = \"none\";\n",
        "      document.body.appendChild(transfer);\n",
        "\n",
        "      //window.arr64 = [];\n",
        "      //window.arr224 = [];\n",
        "\n",
        "    }\n",
        "\n",
        "    async function capture(){\n",
        "        return await new Promise(function(resolve, reject){\n",
        "            pendingResolve = resolve;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            result = canvas.toDataURL('image/jpeg', 0.8);\n",
        "            pendingResolve(result);\n",
        "        })\n",
        "    }\n",
        "\n",
        "    function showimg(imgsourceb64){\n",
        "        img64.src = \"data:image/jpg;base64,\" + imgsourceb64;\n",
        "    \n",
        "    }\n",
        "\n",
        "  ''')\n",
        "  display(js)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCE_b0xcJJXo"
      },
      "source": [
        "#this button click function is borrowed from Mr. Seyed Farzam\n",
        "\n",
        "def ClickTracker():\n",
        "  js = Javascript('''\n",
        "\n",
        "    // Add a button under the images for clicking and save the image\n",
        "    async function JSSaveImage() {\n",
        "      button = document.createElement('button');\n",
        "      button.setAttribute('content', 'Click to Save Image');\n",
        "      button.setAttribute('onclick', 'savejs()');\n",
        "      button.innerHTML = 'Click to Save Image';\n",
        "      \n",
        "\n",
        "      input = document.createElement('input')\n",
        "      input.id = \"inputLetter\"\n",
        "\n",
        "      document.body.appendChild(input);\n",
        "      document.body.appendChild(button);\n",
        "    } \n",
        " \n",
        "    function  savejs() {\n",
        "      document.getElementById(\"transfer\").innerHTML = \"photo is saved\";\n",
        "    }\n",
        "\n",
        "    // in each iteration the python code execute this function and based on the message save the images or not\n",
        "    async function  checkForSave() {\n",
        "      decide = document.getElementById(\"transfer\").innerHTML;\n",
        "      document.getElementById(\"transfer\").innerHTML = \"waiting\";\n",
        "      if( decide == \"photo is saved\") {\n",
        "          return true;\n",
        "      }\n",
        "      else {\n",
        "          return false;\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function getLetter() {\n",
        "       decide = document.getElementById(\"inputLetter\").value;\n",
        "       return await decide\n",
        "    }\n",
        "\n",
        "    ''')\n",
        "  display(js)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtoMIZRrNO5m"
      },
      "source": [
        "Finding the best HSV masks\n",
        "\n",
        " the HSV mask should be different in different enviroment, so it's better to find the best combination each time before saving images\n",
        "\n",
        " The following HSV related function come from Seyed Farzam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUpIbCzONGte"
      },
      "source": [
        "def HSVJSPANEL():\n",
        "  js2 = Javascript('''\n",
        "    // Add a button under the images for clicking and save the image\n",
        "    async function PanelHSV() {  \n",
        "      heading1 = MakeHeader(\"from\", 'h6');\n",
        "      h0 = Makeinput(\"h0\",0);\n",
        "      s0 = Makeinput(\"s0\",0);\n",
        "      v0 = Makeinput(\"v0\",0);\n",
        "      document.body.appendChild(document.createElement('br'));\n",
        "      document.body.appendChild(document.createElement('br'));\n",
        "      heading2 = MakeHeader(\"to\", 'h6');\n",
        "      h1 = Makeinput(\"h1\",255);\n",
        "      s1 = Makeinput(\"s1\",255);\n",
        "      v1 = Makeinput(\"v1\",255);\n",
        "    }\n",
        "    function Makeinput(id, value){\n",
        "      input = document.createElement('input');\n",
        "      input.setAttribute('type', 'number');\n",
        "      input.setAttribute('min', '0');\n",
        "      input.setAttribute('max', '255');\n",
        "      input.setAttribute('value', value);\n",
        "      input.id = id;\n",
        "      document.body.appendChild(input);\n",
        "    }\n",
        "    function MakeHeader(text, type) {\n",
        "      heading = document.createElement(type);\n",
        "      heading.innerHTML = text;\n",
        "      document.body.appendChild(heading);\n",
        "    }\n",
        "    async function GetResult() {\n",
        "       var result = {\n",
        "         \"h0\" : document.getElementById(\"h0\").value,\n",
        "         \"s0\" : document.getElementById(\"s0\").value,\n",
        "         \"v0\" : document.getElementById(\"v0\").value,\n",
        "         \"h1\" : document.getElementById(\"h1\").value,\n",
        "         \"s1\" : document.getElementById(\"s1\").value,\n",
        "         \"v1\" : document.getElementById(\"v1\").value\n",
        "       }\n",
        "       return await result\n",
        "    }\n",
        "    ''')\n",
        "  display(js2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aipn4CDrNvzI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "4d642519-52bb-434d-ad7f-9c6ac5b8bbd1"
      },
      "source": [
        "#run this one and modify to get the best numbers for masks\n",
        "def HSVTunner():\n",
        "  HSVJSPANEL()\n",
        "  eval_js('PanelHSV()')\n",
        "  VideoCapture()\n",
        "  eval_js('create()')\n",
        "  prob=[]\n",
        "\n",
        "  while True:\n",
        "      byte = eval_js('capture()')\n",
        "      im = byte2image(byte)\n",
        "      dichsv = eval_js('GetResult()')\n",
        "      fromhsv = np.array((float(dichsv['h0']), float(dichsv['s0']), float(dichsv['v0'])))\n",
        "      tohsv = np.array((float(dichsv['h1']), float(dichsv['s1']), float(dichsv['v1'])))\n",
        "\n",
        "      hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "      mask=cv2.inRange(hsv,fromhsv,tohsv)\n",
        "      hist = cv2.calcHist( [hsv], [0], mask, [16], [0, 180] )\n",
        "      cv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX)\n",
        "      hist = hist.reshape(-1)\n",
        "      prob = cv2.calcBackProject([hsv], [0], hist, [0, 180], 1)\n",
        "      prob &= mask\n",
        "      #prob = camshiftTracker.checkProbability(im, fromhsv, tohsv)\n",
        "      eval_js('showimg(\"{}\")'.format(image2byte(prob)))\n",
        "HSVTunner()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-2854a49f4059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;31m#prob = camshiftTracker.checkProbability(im, fromhsv, tohsv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'showimg(\"{}\")'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage2byte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mHSVTunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-112-2854a49f4059>\u001b[0m in \u001b[0;36mHSVTunner\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mprob\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;31m#prob = camshiftTracker.checkProbability(im, fromhsv, tohsv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'showimg(\"{}\")'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage2byte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mHSVTunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: Cell has no view"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Kb9Zu_TR9kz"
      },
      "source": [
        "Following three cells are just for creating and changing directory in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrFyBLGoX6Ox",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abe4a27d-110b-4b96-a397-3c39a792ebe5"
      },
      "source": [
        "cd drive/'My Drive'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O1gamrqYGAf"
      },
      "source": [
        "#create a folder\n",
        "os.mkdir('yourhand')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd4hFfuyYgS9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eda5ab16-d500-4709-e9c3-343b281b7877"
      },
      "source": [
        "#change directory to this folder\n",
        "cd 'yourhand'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/yourhand\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc7MFqYo7bv2"
      },
      "source": [
        "#Create dataset\n",
        "Next step is taking photo, detect and save.\n",
        "\n",
        "Input the letter you want to save, then click button will save two probability images, 16* 16 and 224* 224\n",
        "\n",
        "Set the starting number of the file name here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEc5a1Z9DGym"
      },
      "source": [
        "# this function for creating our dataset\n",
        "def getphotos():\n",
        "  # run JS function for capture the video stream\n",
        "  VideoCapture()\n",
        "  eval_js('create()')\n",
        "\n",
        "  #run JS script for click and save the image\n",
        "  ClickTracker()\n",
        "  eval_js('JSSaveImage()')\n",
        "\n",
        "  show_backproj=False\n",
        "\n",
        "  #Initialize lists\n",
        "  rects=[]\n",
        "  track_window_hand=()\n",
        "  prob16=[]\n",
        "  prob224=[]\n",
        "  ############set the starting number of the file name #######################\n",
        "  num=0\n",
        "\n",
        "  while True:\n",
        "    byte = eval_js('capture()')\n",
        "    im = byte2image(byte)\n",
        "\n",
        "    vis = im.copy()\n",
        "    imcopy=im.copy()\n",
        "\n",
        "    # load input image in hsv mode:\n",
        "    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "    mask = cv2.inRange(hsv, np.array((25., 30., 30.)), np.array((180., 180., 204.)))\n",
        "\n",
        "    new_track_window=None\n",
        "\n",
        "    # check if there's face been detected\n",
        "\n",
        "    if len(rects):\n",
        "  #locate the position of face and define an area\n",
        "        for rect in rects:\n",
        "          x11,y11,x22,y22=rect\n",
        "          #set the margin as 20% of the height plus 30 pixels\n",
        "          pad=int(0.2*(y22-y11))+30\n",
        "          x1=x11-pad \n",
        "          # the space should lie inside the video screen\n",
        "          if x1 <0 :\n",
        "            x1=0\n",
        "\n",
        "          y1=y11-pad\n",
        "          if y1 <0:\n",
        "            y1=0\n",
        "\n",
        "          x2=x22+pad\n",
        "          if x2>im.shape[1]:\n",
        "            x2=im.shape[1]\n",
        "\n",
        "          y2=y22+pad\n",
        "          if y2>im.shape[0]:\n",
        "            y2=im.shape[0]\n",
        "\n",
        "          #back projection records how well the pixels fit the pixels of a histogram \n",
        "          prob = cv2.calcBackProject([hsv], [0], hist, [0, 180], 1)\n",
        "          prob &= mask\n",
        "          term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
        "\n",
        "          track_box, track_window = cv2.CamShift(prob[y1:y2,x1:x2], track_window, term_crit)\n",
        "\n",
        "          if track_window is not None:\n",
        "\n",
        "            xx,yy,ww,hh=track_window\n",
        "\n",
        "            rect=[xx+x1,yy+y1,xx++x1+ww,yy+y1+hh]\n",
        "\n",
        "          #if can't find the face in that area we search for the whole screen\n",
        "          else:\n",
        "\n",
        "              xr1,yr1,xr2,yr2=rect\n",
        "              track_window=(xr1+x1,yr1+y2,xr2-xr1,yr2-yr1)\n",
        "              track_box, track_window = cv2.CamShift(prob, track_window, term_crit)\n",
        "\n",
        "              xx,yy,ww,hh=track_window\n",
        "              rect=[xx,yy,xx+ww,yy+hh]\n",
        "            \n",
        "        # set the probability of face as zero \n",
        "          xp1,yp1,xp2,yp2=rect\n",
        "          prob2=prob\n",
        "          prob2[yp1:yp2,xp1:xp2]=0\n",
        "\n",
        "          if show_backproj is True:  \n",
        "            imcopy[:] = prob2[...,np.newaxis]\n",
        "      \n",
        "          #use the histgram we already get to find the hand\n",
        "\n",
        "          track_box_hand, track_window_hand = cv2.CamShift(prob2, track_window, term_crit)\n",
        "          xx,yy,ww,hh=track_window_hand\n",
        "          rect_hand=[xx,yy,xx+ww,yy+hh]\n",
        "\n",
        "          draw_rects(imcopy, rect_hand, (0, 255, 0))   \n",
        "\n",
        "          #the position of the hand \n",
        "\n",
        "          hand_prob=prob2[yy:yy+hh,xx:xx+ww]\n",
        "\n",
        "          #prob16 is for storing the probability of 16*16 image\n",
        "          #prob224 is for storing the probability of 224*224 image\n",
        "\n",
        "          prob16=cv2.resize(hand_prob, (16,16), interpolation = cv2.INTER_AREA)\n",
        "          prob224=cv2.resize(hand_prob, (224,224), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "                                                                          \n",
        "  #before we track the histogram, we first need to detect the face and get the position\n",
        "\n",
        "    else:\n",
        "\n",
        "    \n",
        "          gray = cv2.cvtColor(vis, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "          #use Cascade classifier to detect the face\n",
        "\n",
        "          rects = detect(gray, cascade)\n",
        "\n",
        "          if len(rects)>0:\n",
        "\n",
        "            for rect in rects:\n",
        "              x11,y11,x22,y22=rect\n",
        "\n",
        "            track_window=(x11,y11,x22-x11,y22-y11)\n",
        "            hsv_roi = hsv[y11:y22,x11:x22]\n",
        "            mask_roi = mask[y11:y22,x11:x22]\n",
        "\n",
        "            #calculate the histogram\n",
        "            hist = cv2.calcHist( [hsv_roi], [0], mask_roi, [16], [0, 180] )\n",
        "            cv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX)\n",
        "            hist = hist.reshape(-1)\n",
        "            vis_roi =vis[y11:y22,x11:x22]\n",
        "            cv2.bitwise_not(vis_roi, vis_roi)\n",
        "            vis[mask == 0] = 0\n",
        "\n",
        "            #set the margin as 20% of the height plus 30 pixels\n",
        "            pad=int(0.2*(y22-y11))+30\n",
        "            x1=x11-pad \n",
        "            # make sure the space lie inside the video screen\n",
        "            if x1 <0 :\n",
        "              x1=0\n",
        "\n",
        "            y1=y11-pad\n",
        "            if y1 <0:\n",
        "              y1=0\n",
        "\n",
        "            xx,yy,ww,hh=track_window\n",
        "            track_window=(xx-x1,yy-y1,ww,hh)\n",
        "\n",
        "            #for subrects in rects:\n",
        "              #draw_rects(imcopy, subrects, (0, 255, 0))\n",
        "          else:\n",
        "            print(\"no face detected\")\n",
        "      \n",
        "    eval_js('showimg(\"{}\")'.format(image2byte(imcopy)))\n",
        "    shouldISave = eval_js('checkForSave()')\n",
        "    \n",
        "    if shouldISave:\n",
        "          letter = eval_js('getLetter()')   \n",
        "          #count the number of images \n",
        "          num=num+1\n",
        "          #save two files for each images\n",
        "\n",
        "          filename16=letter+\"_\"+str(num)+\"_\"+str(16)+\".jpg\"\n",
        "          filename224=letter+\"_\"+str(num)+\"_\"+str(224)+\".jpg\"\n",
        "          im1 = Image.fromarray(prob16)\n",
        "          im1.save(filename16)\n",
        "          im2 = Image.fromarray(prob224)\n",
        "          im2.save(filename224)     \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak8pzXZsFg1m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "495756fb-131e-4b9e-c0ff-0d59d1923e76"
      },
      "source": [
        "#call the function to start building our dataset\n",
        "getphotos()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-c8aa67e1a1b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetphotos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-122-3547274b6e5c>\u001b[0m in \u001b[0;36mgetphotos\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mbyte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'capture()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbyte2image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: Cell has no view"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKWxDeB471-e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "outputId": "79b4ce49-e125-48f6-9d5c-2e5720f2af36"
      },
      "source": [
        "#display some images\n",
        "display(Im('A_100_224.jpg'))\n",
        "display(Im('B_100_224.jpg'))\n",
        "display(Im('C_100_224.jpg'))\n",
        "display(Im('D_90_224.jpg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCADgAOABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiin7x6UhbIptO2H1pCMUlFFFFWdPs21DU7WyRwjXEyRBj0BYgZ/Wus+IXw4vPh7Lp6Xd/Bdm9EhUxKRt2beuf96uKoor1L9n/wD5KfH/ANec39K+l9c0iTVVgEcqx+WWzuHXOP8ACua1PQZdMtRO8yOC4XCg+h/wrkfFGjya/wCHLvTIpViecLh3GQMMG/pXzdcQm3uHiJBKMRke1RUUUUUUUUUUUu45oJzSUUUUU+KWSCZJYXaOVGDI6HBUjkEHsa9e0rTdZ+MvgyWOaV5NW8PKkVo8kpJuvNbLmVnycgJxivPPE/g/V/CF/wDYtWijSbaGxHIHGD06fSsEgjqMUV6h8AnVPidGWYKPsc3JOPSvq+obm2iu4GimRWU9NwBwfUe9cjrHh37Bb+fA7PGv+sLkZHIAx+dfJPiJNOj1qcaZcTTwZyXmXDbsnI+lZVFFFFFFFFFFFFFFFFFKrFHDKcEHIrqdA+I/inwws66RqKwCcqZM28b5xnH3lOOpqxea/wCJfE+ri/1m63ybVBcwIm5R2+UCsbxF/r4f90/zrGrv/g5oGm+JPiBDY6rbme3WB5godk+dcEHKkGvsCiorm2iu7d4Jl3RvjIzjvmvkP4w+HtM8M+PpbDSbcwWxt45ShkZ/mbOTliTXA0UUUUUUUUUUUUVs+GfC+p+LNWj03TI0MzhjvlbagwCeW7cCt/8A4VR4m/u2n/f7/wCtTo/hP4jMih1tQmRuxNzj8q7TUvgRFH4fmv7C7uGn2ExJPKgBOcc/LmvGLyznsLqS2uY2SRGKkEEZwcZHqOK7j4Z/DO68d6oXuDJBpEBAuZUYLJ8ytt2ZBB+ZRmvqeHwl4ehgji/sTTW2KF3NaRknA6nivD/2gNJ0+wm04WGn2tsWhJPkQqmfnHoK8JroPBd5c2Pie2mtbmW3fO0vE5Q4JGRkdq+3UkSVA8bq6noynINOpCQoyxAHqa+dvjteRX+j2dw1jZpdfbAhuY4gJGUI2FLdSPavCqKKKKKKKKUEdxQcdhikoqSCCW6uIreBC8srhEQdWYnAH519C+AfDl14U8MGCS+EjajsuJ7fytpgYD7pOTk/TFdJSglWDDqDkVZvNSu78ILqbzNmdvygYz9BWBr/AIa0jxPfR3us2guriOFYEcyMmEBJAwpA7mvQ/BVpBp+hRWFpMptrdQscAB/cjJOMnk5966SvEfjn/wAhnSf+vd//AEKvm6trQLUtI11v4XKbce1fW3wu/wCScaR9Jf8A0a9dVcu0drM6nDKjEH3xXA3GtahdwNBPcb426rsUZ5z2Fcf410uy1PwrfteQ+abW3lnh+Yja6o2Dwefx4r5zoooooooorT0HQrvxFqQsLIxCYoX/AHjYGB+Br07S/hBp7abCdVurtb3nzRbyr5fU4xlM9MVq638MtH1NFkiaeCeG2EMaxFERioOC3y8kk8mvGNX0e80TUJbK8TEkZxuXO1voSOetafgO1luvHvh8RwPMqalbNIFQsAvmrkn2r7W+w2n/AD6wf9+xXLeKJLRZEtYYVjljOXKoACCOK52iipI55oc+VK6Z67WIzT/t13/z9T/9/DXBfECG/wBQvrNkiubnbGwyFZ8c14nqNotndtGm8oAMFu/Fdv8AB/VbOw8ZJFqNiby1kiceWsAlO44AODxj3r65gt4bWFYbeGOGJfupGoVR34Arz68u7n7XcL9om2+YwxvOMZqlTZI0ljaORFdGBVlYZBB6givGfi5ZWtlqmmra20MCtCxYRRhQTu74rzqiiiiiiprS1nvruK1tozJPKwREHViegr3PwL4Ig8O2kd5cgSalKoYsVKmEMozH94g4Oea230zV21/7auuMthuB+w/Z1xjbgjfnPXmtmqN7oOiaxdW8utaYl8kG4KjSMnXryp9h+VdF8M/h5Y+DLKa58kHUp2dTPgqfKJBVMbiOMDnrXc3FxDawmadwkY6sa4nxN/yHJv8AdX+Qrn77ULTTLcT3kwhiLBAxBPJ6DirNFFFdd4P/AOPW5/3x/KvPvit8KtEPhC41PSUTTn02OS5dVVpPPAX7uS3y/XmvIvg9qOo6Z4/hn0zSH1ScwOhgSYRkKcZbJB6elfYVeaXn/H9cf9dG/nUFSm3mW2W4KHyWbaG9T6V4z8Zf+Qtpn/XBv/Qq8zoorofD/grW/El6bW0tHjPlGUPPG6oRkDghT616/H+z5b3PgaOWG4lTxK0anEs+LYNv542bsbc/jXkXjDwRrHgnUhZ6pGj5VWE8AZoiTk7QxUc8dK5yvRfhEbQa1e/aTB5nlp5PmYzu3fw57/SvaKKKuWOoyWAcJDBJvxnzU3Yx6V1Wja/HeoY7kpHMoJzwq49snrRrepaaYBa3DSSJJ82YCpxg/WuB1PUUsLC41C6MjpBGXfHLED0ya8q8XeItXupbKzuVtPsF60d5beWreYIy3yBsnG7HXFeu0UUV13g//j1uf98fyroZYo54mimjSSNxhkdQQw9CDWF4d8F6N4YudQuNPg/e3t09y7Oqkxl+qoQBtT0FdBXml5/x/XH/AF0b+dOsrGfULhYYV5P8RztHGeT+FaEyN/wjMEYGW+1sMDucGvD/AI4R2cepaILedZJvsrfaEDgmN93QgdD7GvKaK6fwL4fk13xFButBcWMDg3QLAAKQcZ5yeR2r6m8PWL6U8KxRZm8sKttnG2HjD5/DGOtdlXlXx80LUta8DwNp1qZxY3BurghlHlxLG+5uSM49BzXyrW54O/5HLR/+vpP519I0UVLLbTQxRSyJtSUEocjkCoqKiubaG8tpLa4jEkMqlXQ9CD2rCvPB2n3us2V5MqtbWlsLeO1KnAwcqc57V0VFFFdd4P8A+PW5/wB8fyrpKKpavNJb6VcSxMVdVyGHbmuBg/fX0XmfNvkG7PfJ5rvlhsdIt5ZlRYIuN5GT7D+dVYtFUW1uguCRFcC4B2de+OtfIHxJ/wCSleI/+v8Al/8AQq5aivYvgLpM+q3OuiF418tIM7ye5f0HtX0Xp2nSwyLcXbI1wsfkqYyduwYx171pVxnxS1tdG8BaopsL67+22s9qDaxbxDuib55OflQdzXxnW/4HMQ8c6IZwxi+2R7wnXGe1fTVvZ/b72SK1IVBudfMPO0euO9P0zSZ9VMoheNfLxneT3z6D2rb0/wAKyRXQkvJI2jXkCNjndkY6jpV3XdGm1M2/2dokEQYENkdcdMD2rm9S0O50uBJZpImVm2gITnOM9xWZRRRRRVqwsW1CcwpNFG2MjzWxnnGB710FpKvhdWhvAZGmO9TDyABxznFb9jex6haLcRKyoxIAbrwcVZqK6t0u7Z4Jc7HGDg8150dlrqPcpFN+OAa7KPX7O5sbm48mUxwbd6soycnAxzXO+JfirovhWxhuryzv5I5JPKUQohIOCe7DjivlPxbq8Gv+LtW1a2SRILy5eaNZQAwBORnBIz+NY1Fe9fsz/wDH34l/3Lf+clfQtFYHjn/kn/iT/sF3X/opq+H63PB3/I5aP/19J/Ovqjw5/wAhN/8Ari/8q0PB337z6J/WurornvF//IOg/wCuv9DXHUUUUUU5HaORZEJV1IKkdiKluby4u2VriVpCowC3au08M/8AIDh/3m/ma16K80vP+P64/wCujfzrQsP+Re1X6xf+hV5H8Yv+Rbsf+vwf+gNXi9FFek/BLxHqGkePbTTLRoxbapKsdyGTJIUMRg9upr62orA8c/8AJP8AxJ/2C7r/ANFNXw/XUfDcA/Erw4CMj7fF/wChV9LT3ctjrV5JBtDebIvIzwSaqWtzLaXCTQnDqcjPSul8N6vFiS2uH2yu7Sb2YBTnAwPeunrlfFl6jbLIK29GEhbtjBrl6KKKKKKmhtbi4BMMEsoHBKIWx+VdjoVxBZaVHBdTRwTKWJjlYKwyfQ02x8QxSX1xb3EiBRI3ly5AXaDxznmtP+07D/n9tv8Av6v+NcCypNqpXOUefGQeoLV1GpaZbaboF6LcMN+zdubPRh/jXhfxjikHhawlMbCM3oAfHBOxuM14pRRXZ/Cb/kqfh/8A6+T/AOgtX2ZRWB45/wCSf+JP+wXdf+imr4frqfht/wAlK8Of9f8AF/6FX0dqX/IVvP8Aru//AKEaq0+KQxTJIBkowbH0rqTrs99ol9Mq+RJDs2sjHPLVy89xLcyeZNI0j4xuY5NR1tRWMNxpmmLtCPPOyNIBzjNan/CHwf8AP3J/3yKP+EPg/wCfuT/vkVzeoWMun3RhlGD1XkHK5OD+lVafFG00yRIMu7BVHqTXa+HNPudPgnW5QIXYEYYHt7Vz3ib/AJDk3+6v8hWRRU9n/wAf1v8A9dF/nXpEsMc8TRSoro3VWGQa8Y/aKt4rbwNpUcMaxp/aQO1Rgf6t6+aquaVZJqOq2tlLdwWaTyBGuJ2xHED/ABMewFM1C1Sx1K6tI7iK5SCZ4lnhOUlCkjcp7g4yPrWp4M12Hwz4w0zWriF5orSXe0cZAZhgjjP1r7Z0+8XUNNtb1FKJcQpKqt1AYA4P51ZrA8c/8k/8Sf8AYLuv/RTV8P1638AfDuna34suru9jd5tNSO4tirldr7upx1r1zUv+Qref9d3/APQjVWitew/5F7VfrF/6FWRWholpFe6pHBOCY2DEgHHQV6FgelIzKilmICgZJPYVlWvinQL25jtrXWrCeeQ4SOO4VmY+wBrVwD1Ao2j0FGB6ClrhPE3/ACHJv91f5Csiitfw5aRXeqbZgSETeuDjkEYru68Z/aR/5ErSv+wiP/Rb18zU+JxHKrlFcKc7W6GtKZo7nSJJxaxRMsoXKLjtVjwbd6TY+L9NutdiSXS45c3CPF5gZcHqvfnFfbOnyW02mWstmoW1eFGhULtAQgbRjtxjiuQ1nUL2HV7lI7qdEDcKrkAcVr+MyT8OfEJJyTpNz/6JaviGvqTSbCy0OSSXSLaGyeUbXa2QRlgOxI61praz3ERu3OUMoVmJ5LGu3tdEsLe3SJreKUrn53QEnnvUv9l6cP8Alyt/+/YrnvFEaWawRWqLDHKG8xYxtD4xjOOtc1UkMssEgkhdkcdGU4NenV8z+K/FfiGHxJrlvFreoJAl3OixrcMFVQ7AADPTFeTWus6nZXMdza6hcwTxnKSRylWU+xFeh+C/Gnii8v7FbnxDqkyveojCS6dsqWXg5PSvq6iiq8thZzyGSa1hkc9WZATVO8t9IsIPOntIFTIHEQNPtbPSry2SeGzgMb5wTEB3xWFeS2KanC+nO8MwkWJ4402KRnn+lddXy5+0FqV8/jz+zXvJ2sY7eKVLYyHy1chgWC9M4715HU9nGs15DG4yrOARXuvhvwlJ4r+Duq6VbXKWxivxMGdSwwka8V414X0GTxP4lsdFhnSCS7k2LI4yF4J5A+lfbulWbafo9lZM4dre3jiLAYBKqBn9KS90y01EobmMvsztwxGM/SqHi61muvA+u2drE0s0um3EUUaDLMxjYAD3Jr4ivLO50+8ms7uF4LmFikkUgwyMOoIr7B0P4d2uhW0FlbOoso2LeXliTk5PJOa6ibRrG4MJkiJ8lAifORgDpV+uXt7S4vNckuNThcQxKTG5G0DDZHT8axvFWtTXesWVtaabcXFovmCa9j5ji4BG76ngU3StMfVLh4kkWMqu7JGe+P61seH9KeHVppTKpFs5jIx97I61qeKb640zwrql9aOEuILZ5I2IBwwHHBr5O1vVJZHutQuv3k1xKzyEADLMSScfU1xFdr4C/wCQjp//AF/x/wDoS19lUVz3iPVbvT54FtpAgZSTlQe/vWJ/wkuqf8/C/wDftf8ACqV7f3GoSrJcuHZV2ghQOPwqxba5qFpbpBDMFjTOBsB759KtW3iLU5LqFGnUqzgEbF6Z+ldvXyN8btVsNY+Istzp13DdQC2jjMkTbgGGcj6ivOavaVMIr6MGNG3sBlh933FfaPg2xs7fwZpQgtYI1uLKGSYJGAJGMa5ZsdSfU1Sn+HPh06/pGr2Nhb6bPpkjyKtlbxxCYsAMPhckDt9TXW0VneINQm0nw3qmpW8ayz2lnLPGjAkMyIWAOOeSK+I/EGq3GueIL/VLqFYbi7naWSNAQFYnJAzzX3bRRSEBlKsAQRgg964zV9f0fwbeTJrEZWC/O6COOLepCYzkduWFdRZDT2Als0t1LoD+7VQcH1xVlIo42dkjVS5yxUY3H1NeP/GHxXE6xaLYXtwk0bE3SxMVSRGUYBIOGHPSvC9cBOmnAz84rl67XwF/yEdP/wCv+P8A9CWvsqiuR8Yf8fVt/uH+dc3RRU9n/wAf1v8A9dF/nXSfEDxPN4Q8F6hrNqkEt1bhDHFMTtfMiqeAQejV8V3ExuLmWdgA0jlyB0BJzUdFfcHgb/kn/hv/ALBdr/6KWt+iiivin4k/8lK8R/8AX/L/AOhV9pSTxQtGsjhWkO1Ae5qSvPviH8Q4vDlu+nabKrao4KllIJtjhSCykEHINeW/8LV8af8AQZ/8lYf/AIiuU8V/EDVNamt11a6+2vAGCYRI9mcZ+6oznA/KpPCvi3VNIaS/0if7JLIpiYlFfK5Bx8wI6gV6NdfGbUZPDkdpbwvFqwVA18djBiCNx2bcc815dTZGRUO8gKeOapf2NYf88P8Ax9v8a2fDVtFa67pscKbVN5EcZJ53D1r67oqneaXZ37q1zDvKjAO4jH5Guf8A+EPk/wCfxP8Av2f8aP8AhD5P+fxP+/Z/xo/4Q+T/AJ/E/wC/Z/xqG78PPpNlPqTXCyLaRtOUC4LbBuxnPGcV86fFH4kQ/EObS3h02Sy+xLKCHlD79+30Axjb+tee0UV9S/ACe+bwLeNfXUs6x3WIRJIX8uMRJhRnoB6DivTNP1a21MyC33/u8Z3DHX/9VXqKzvEFrd33hvVLSwk8q9ns5YreQOV2yMhCncORgkc18rah8IvGf/CU2ul3hgnv9QR5hO07Op28ne5HU/rX0S2ga05UvcBipypMxOD7VRk+K3h7SpX068N611aMYJisQYF0+VsHPPINeJ+PfEFlrHi++1S1837PcFNm9cN8qKpyPqK5K91WOO2Pl7tzccjpxXNgPPLgsWdu7Guh0mVbe2WB87y/bpzWtRXaRfCHxPq2lWt5bGx8q4jSZN8xB2sARnjrg1e/4U14q9bD/v8An/CrWmfCLxPaatZ3MpsvLhnSRsTEnAYE9q95orDbUBo93c/bnkZZ5C8QX5sL/Sl/4SrTv+m3/fH/ANetDT9Rg1KFpYN21W2ncMc1g+M/H+i+BI7N9Y+04uy4i8iMP93Gc8j+8K+TNZ8Za5f6pqDw67qv2OeaQpE13IB5bMcKVzjGDjFc5RRRX038C9Usk8K3GmNcKL2RvNSHnJQRqCa7nwd9+8+if1rq6K8d1P42N5N5aW2jPDcbXjjn+0htjcgNgpzg84rzK4+NnjGC4ki/tKRtjEZ8uLn/AMcrv3+PMmqaLN9j0V7K4lRljm+1B/LboGwU5+leX3VzNe3c13cPvnnkaSR8AbmY5J49zWfqEPmQ792NmTjHWuXmnZ1aNuSHzmo4pPKlD4zjtWzpzrcSI7NswwwOuTnpW9Xp3gPwTbeKNOsZrnSzbw28pkmu2csL1dxHlgAjZj1r3K1tobK0htLdNkEEaxxpknaqjAHPsKlooorkfGH/AB9W3+4f51z0UTzSrFGpZ2OFA7mu70LTn02w2SNl5CHIxjaSBxXjP7TH/Hp4a/37j+UdfPVFFFFeu/Aa6hj8WkXVykamGRQZHA6gcDNfQui2IsNU1CGMP5QEe1n78Enn8a3a8w+MXiXUNHsLPTbJljjv1cySjcJF2MhG0gjHvXg8zsI5JM5YAtk9zXG3bmS7lc4yWJOK1fD7sJZVZjt2jaCeOvat+o54zLA6LjJHeuX1K2eC5ClR93Py9O9Ua6PQoU+x+aRltxHNa9fWPh7QbTw1o0Wl2TzPBEWKmZgW5JJ5AHrWjLIsMLytnailjj0Feef8Lq8Mf88NS/78r/8AF0f8Lq8Mf88NS/78r/8AF0f8Lq8Mf88NS/78r/8AF0f8Lq8Mf88NS/78r/8AF1u+Hde0bxs76hZx3OLQ+UVuEUA7hnpk5ro1tbdGDLBEGHIIQAimX1/a6bZyXV3NHDCgJLOwXPsM96+NviR4rj8X+M77UrSa7OnSFDbw3Bx5eI1VsLkgZKnpXJUUUUVa067kstQguIiQyOp+oz0r7R8HeMrLxfpvnwhYruMZntgxbysswX5sAHIXPFdJXn/xR8GXfijT7e7sHL3VkrBLYIP329lz8xIAwAT3zXz3LGVZ4pFwQSrD+dYWoaKWDS25y2f9WB1/HNRaABJNIG5CAFfY5roaKr3VolyvJ2t0zjPHpXOanZizkRQuAc4PrRYapJY5Ur5keOEzjB9elXv+Ej/6df8AyJ/9avfdL/aC0y+1S2tbjTUtoZZAjzfaWbYD3x5fNdlffErwg1hcqmtRMxiYAeXJycH/AGa+UP8AhI/+nX/yJ/8AWo/4SP8A6df/ACJ/9atOxu5LyIyPB5SnG07s7qtU1vGviLwsfJ0TVJbOOb55FRVO4jgHkGus0b4teKI9Rhkvr+WYQuHmtGKjeuem4Lxmk+JXxdg8Y+FpNFXTBbSC4Ry4uC+NucjGwfzrxyiiiiiiu/8Ahv8AEy68D6qBNGJdNnKi6CR7pSo3EbcsBnLd6+uLG7j1DT7a9iDLHcRLKgcYIDAEZ9+asVw/in4ZaR4hkub5BJDftAUhCOEi3gHaWAUnGeteef8ACkfEv/P7pP8A39k/+N118fwg8FbwsV1c7m4AW5TJ/wDHasf8KY8Lf89NQ/7/AC//ABNcz41+EkWnaUL3w+ZpPJDNPFM5d3HG0IFXk9c5ryV1aJmWQFGUkMGGCCOua53X5Y5Gt/LdWwGztOfSsainwytBMkqY3IcjNaJ1y8cFdsZyOyn/ABrPt4WuJ0hQgMxwM9K2bTQXScNcshQcgITnP4itwAKMAAD0FLXPeIv9fD/un+dZs93NcTtMzbXYAHbxUBJJJJyTRRRRRRRXsfwE8LaH4mudeXWtNhvRAkBiEufkyXzjH0H5V9MQQRW1vFbwoEiiQIijoqgYA/KpKKK85+JmsW3gzQo7izskSe4LolwrEGAgZDAYOTXg2pfFnxaZFFn4ju9uOSMDn8RVST4s+OHxt8RXiY9GHP6Vy8+r6hdSSyTXUjvKSzk/xE9apUUVZgiImKPEG9cnpVwQxpkqgBxWfia1dZBlGH3SDU39p3v/AD8vR/ad7/z8vR/ad7/z8vUM1zNckGaQuRwM1FRRRRRRRRXuX7N1/Z2up67b3F3BDPcLAsEckgVpSPMyFB5bHtX0bRRRXxJ4k8ca14qvZrrU5ImeVQrLGm1RgY4GeK5uiiiinIm9gu4L7mtOKVJV3L19O9SUEA9RUckKSLtYcZzxVeSyBx5Zx65NQyWkkYB+97LULKy/eUj6ikooooooooqzYahd6XfQ31jcSW91Cd0csZwyn1Br6++FPjC58a+DRqF3AIpreY2rEOWMm1EO8k9zuruKKK+AKKKKKKK09Gns4JZTeY2lRtypPP4V04trSS3EqQoVZdynHYiueooqJ7iONtrNg/Ss+eQySk5JXPFR0UUUUUUUUV9Dfs6+Kbb7HdeFPs8v2rfLf+dxs2YjTb65zXvNFcb8UvEWo+FfAV7q+luiXcUkSqzoGGGcA8H2NfGVFFFFFFdh/wAI9p/9x/8Avs1oiNYbYRp91E2j6AVyrOqfeYDPqajkuY0XIYNz0U1XkvSceWMeuaqE5OTRRRRRRRRRRRXoXwc8VaT4P8ZT6jrM7w2z2TwhljZzuLoQMAeimvdf+F7eAf8AoKT/APgJJ/hR/wAL28A/9BSf/wABJP8ACvN/i78XdL8TaF/YWhYubS4CvPPJG8bRsrggAEc5xXiFFFFFFFasOrTLEBJcylvqas/bbho8ieTBGfvGsX95KpYsWC9cnpUdFFFFFFFFFFf/2Q==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycx7q-JAt3Fw"
      },
      "source": [
        "#save all the 16*16 images to a txt file\n",
        "listoffiles=os.listdir()\n",
        "for file in listoffiles:\n",
        "  if file.endswith(\"16.jpg\"):\n",
        "    aletter=file[0]\n",
        "    imarrayy = np.array(Image.open(file))\n",
        "    imarrayyf= np.append(np.array([aletter]),imarrayy)\n",
        "\n",
        "    with open('dataset.txt', 'a') as f:\n",
        "      np.savetxt(f, np.column_stack(imarrayyf),delimiter=\",\", fmt='%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOnv1eIr2gae"
      },
      "source": [
        "#shuffle the lines\n",
        "import random\n",
        "lines = open('dataset.txt').readlines()\n",
        "random.shuffle(lines)\n",
        "open('dataset.txt', 'w').writelines(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtqiOqiG3PlN"
      },
      "source": [
        "#create two arrays for samples and letters\n",
        "def load_dataset(dataset_file_path):\n",
        "    a = np.loadtxt(dataset_file_path, delimiter=',', converters={ 0 : lambda ch : ord(ch)-ord('A') })\n",
        "    samples, letters = a[:,1:], a[:,0]\n",
        "    return samples, letters\n",
        "\n",
        "samples, letters= load_dataset(\"dataset.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrDM7LrgUMgu"
      },
      "source": [
        "#MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCV0rmrwPSIX"
      },
      "source": [
        "Next we will train the model, the dataset I used is letter A,B,C,D. Each letter has around 200 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg7zsFw03SM6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1263d337-ca02-4e4b-8ac8-f37a1c769b9a"
      },
      "source": [
        "#split the dataset\n",
        "num_classes = 4\n",
        "train_ratio = 0.7\n",
        "n_train_samples = int(len(samples) * train_ratio)\n",
        "x_train, y_train = samples[:n_train_samples], letters[:n_train_samples]\n",
        "x_val, y_val = samples[n_train_samples:], letters[n_train_samples:]\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "x_train /= 255\n",
        "x_val /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_val.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "509 train samples\n",
            "219 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK7rSH_cOl-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71770dc0-9bef-49f8-d907-663718deae4a"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVEgvaLT1WI6"
      },
      "source": [
        "#clear the previouss model built before building a new training model\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5clBBWU3Lff"
      },
      "source": [
        "For the model, I modify the number of neurals to 200, and delete the two drop layers. The accuracy i got is 0.968\n",
        "\n",
        "Following shows the 6 different combinations I have tried and the respect accuracy:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> layer 1: Dense 100   dropout 2: 0.2   layer 3 : Dense 100   Dropout 4:0.2    Accuracy: 0.91\n",
        "\n",
        "> layer 1: Dense 200   dropout 2: 0.2   layer 3 : Dense 100  Dropout 4:0.1    Accuracy: 0.940\n",
        "\n",
        "> layer 1: Dense 100    layer 2 : Dense 100   Dropout 3: 0.2    Accuracy: 0.958\n",
        "\n",
        "> layer 1: Dense 100    layer 2 : Dense 100     Accuracy: 0.963\n",
        "\n",
        "> layer 1: Dense 200    layer 2 : Dense 100     Accuracy: 0.968\n",
        "\n",
        "> layer 1: Dense 300    layer 2 : Dense 100     Accuracy: 0.958"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xyOkM5T3oXl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f4b56bc-3f74-4275-80ce-b5fbac60a3a8"
      },
      "source": [
        "#build and train the model, my dataset only has 4 letters so I set class as 4\n",
        "num_classes = 4\n",
        "epochs = 20\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(300, activation='relu', input_shape=(256,)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_val, y_val))\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 300)               77100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 404       \n",
            "=================================================================\n",
            "Total params: 107,604\n",
            "Trainable params: 107,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 509 samples, validate on 219 samples\n",
            "Epoch 1/20\n",
            "509/509 [==============================] - 0s 236us/step - loss: 0.9359 - accuracy: 0.6582 - val_loss: 0.5883 - val_accuracy: 0.8128\n",
            "Epoch 2/20\n",
            "509/509 [==============================] - 0s 89us/step - loss: 0.4859 - accuracy: 0.8310 - val_loss: 0.6234 - val_accuracy: 0.7763\n",
            "Epoch 3/20\n",
            "509/509 [==============================] - 0s 90us/step - loss: 0.3564 - accuracy: 0.8900 - val_loss: 0.4799 - val_accuracy: 0.8539\n",
            "Epoch 4/20\n",
            "509/509 [==============================] - 0s 97us/step - loss: 0.2411 - accuracy: 0.9312 - val_loss: 0.2948 - val_accuracy: 0.9224\n",
            "Epoch 5/20\n",
            "509/509 [==============================] - 0s 88us/step - loss: 0.2515 - accuracy: 0.9175 - val_loss: 0.2630 - val_accuracy: 0.9178\n",
            "Epoch 6/20\n",
            "509/509 [==============================] - 0s 88us/step - loss: 0.1361 - accuracy: 0.9725 - val_loss: 0.2291 - val_accuracy: 0.9315\n",
            "Epoch 7/20\n",
            "509/509 [==============================] - 0s 88us/step - loss: 0.1871 - accuracy: 0.9371 - val_loss: 0.2053 - val_accuracy: 0.9452\n",
            "Epoch 8/20\n",
            "509/509 [==============================] - 0s 89us/step - loss: 0.0691 - accuracy: 0.9902 - val_loss: 0.2646 - val_accuracy: 0.9132\n",
            "Epoch 9/20\n",
            "509/509 [==============================] - 0s 89us/step - loss: 0.0778 - accuracy: 0.9823 - val_loss: 0.1708 - val_accuracy: 0.9589\n",
            "Epoch 10/20\n",
            "509/509 [==============================] - 0s 87us/step - loss: 0.0450 - accuracy: 0.9921 - val_loss: 0.1828 - val_accuracy: 0.9543\n",
            "Epoch 11/20\n",
            "509/509 [==============================] - 0s 91us/step - loss: 0.0591 - accuracy: 0.9862 - val_loss: 0.1738 - val_accuracy: 0.9543\n",
            "Epoch 12/20\n",
            "509/509 [==============================] - 0s 85us/step - loss: 0.0316 - accuracy: 0.9941 - val_loss: 0.1966 - val_accuracy: 0.9406\n",
            "Epoch 13/20\n",
            "509/509 [==============================] - 0s 86us/step - loss: 0.0196 - accuracy: 0.9961 - val_loss: 0.2342 - val_accuracy: 0.9543\n",
            "Epoch 14/20\n",
            "509/509 [==============================] - 0s 86us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9315\n",
            "Epoch 15/20\n",
            "509/509 [==============================] - 0s 84us/step - loss: 0.0995 - accuracy: 0.9686 - val_loss: 0.1751 - val_accuracy: 0.9680\n",
            "Epoch 16/20\n",
            "509/509 [==============================] - 0s 86us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9635\n",
            "Epoch 17/20\n",
            "509/509 [==============================] - 0s 83us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9680\n",
            "Epoch 18/20\n",
            "509/509 [==============================] - 0s 89us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9452\n",
            "Epoch 19/20\n",
            "509/509 [==============================] - 0s 84us/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.1964 - val_accuracy: 0.9635\n",
            "Epoch 20/20\n",
            "509/509 [==============================] - 0s 92us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9589\n",
            "Validation loss: 0.22892746179615525\n",
            "Validation accuracy: 0.9589040875434875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXeuS3VP3q56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "755f185b-3e52-4795-86ad-1c8b86649a78"
      },
      "source": [
        "#save the model\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model_weights.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTwj_SmF4_v3"
      },
      "source": [
        "#read model\n",
        "from keras.models import model_from_json\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg60Ckfrehhp"
      },
      "source": [
        "#Test the model with non-vgg model\n",
        "\n",
        "\n",
        " \n",
        "Run the function test(), it will print the letter detected. Because I only train the model with four letters, it can only detect 4 letters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nywpoPs80QkB"
      },
      "source": [
        "#this function is almost the same as the previous function for saving the images\n",
        "def  test():\n",
        "  VideoCapture()\n",
        "  eval_js('create()')\n",
        "  show_backproj=False\n",
        "  take=False\n",
        "\n",
        "  #Initialize rects\n",
        "  rects=[]\n",
        "\n",
        "  track_window_hand=()\n",
        "  prob16=[]\n",
        "  prob224=[]\n",
        "\n",
        "  while True:\n",
        "    byte = eval_js('capture()')\n",
        "    im = byte2image(byte)\n",
        "\n",
        "    vis = im.copy()\n",
        "    imcopy=im.copy()\n",
        "\n",
        "    # load input image in hsv mode:\n",
        "    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "    mask = cv2.inRange(hsv, np.array((25., 30., 30.)), np.array((180., 180., 204.)))\n",
        "\n",
        "    new_track_window=None\n",
        "\n",
        "    # check if there's face been detected\n",
        "  \n",
        "    if len(rects):\n",
        "  #locate the position of face and define an area\n",
        "        for rect in rects:\n",
        "          x11,y11,x22,y22=rect\n",
        "          #set the margin as 20% of the height plus 30 pixels\n",
        "          pad=int(0.2*(y22-y11))+30\n",
        "          x1=x11-pad \n",
        "          # the space should lie inside the video screen\n",
        "          if x1 <0 :\n",
        "            x1=0\n",
        "\n",
        "          y1=y11-pad\n",
        "          if y1 <0:\n",
        "            y1=0\n",
        "\n",
        "          x2=x22+pad\n",
        "          if x2>im.shape[1]:\n",
        "            x2=im.shape[1]\n",
        "\n",
        "          y2=y22+pad\n",
        "          if y2>im.shape[0]:\n",
        "            y2=im.shape[0]\n",
        "\n",
        "          #back projection records how well the pixels fit the pixels of a histogram \n",
        "          prob = cv2.calcBackProject([hsv], [0], hist, [0, 180], 1)\n",
        "          prob &= mask\n",
        "          term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
        "\n",
        "          track_box, track_window = cv2.CamShift(prob[y1:y2,x1:x2], track_window, term_crit)\n",
        "\n",
        "          if track_window is not None:\n",
        "\n",
        "            xx,yy,ww,hh=track_window\n",
        "\n",
        "            rect=[xx+x1,yy+y1,xx++x1+ww,yy+y1+hh]\n",
        "\n",
        "          #if can't find the face in that area we search for the whole screen\n",
        "          else:\n",
        "\n",
        "              xr1,yr1,xr2,yr2=rect\n",
        "              track_window=(xr1+x1,yr1+y2,xr2-xr1,yr2-yr1)\n",
        "              track_box, track_window = cv2.CamShift(prob, track_window, term_crit)\n",
        "\n",
        "              xx,yy,ww,hh=track_window\n",
        "              rect=[xx,yy,xx+ww,yy+hh]\n",
        "            \n",
        "        # set the probability of face as zero \n",
        "          xp1,yp1,xp2,yp2=rect\n",
        "          prob2=prob\n",
        "          prob2[yp1:yp2,xp1:xp2]=0\n",
        "\n",
        "          if show_backproj is True:  \n",
        "            imcopy[:] = prob2[...,np.newaxis]\n",
        "      \n",
        "          #use the histgram we already get to find the hand\n",
        "\n",
        "          track_box_hand, track_window_hand = cv2.CamShift(prob2, track_window, term_crit)\n",
        "          xx,yy,ww,hh=track_window_hand\n",
        "          rect_hand=[xx,yy,xx+ww,yy+hh]\n",
        "\n",
        "          draw_rects(imcopy, rect_hand, (0, 255, 0))   \n",
        "\n",
        "          #the position of the hand \n",
        "\n",
        "          hand_prob=prob2[yy:yy+hh,xx:xx+ww]\n",
        "\n",
        "          #prob16 is for storing the probability of 16*16 image\n",
        "          #prob224 is for storing the probability of 224*224 image\n",
        "\n",
        "          prob16=cv2.resize(hand_prob, (16,16), interpolation = cv2.INTER_AREA)\n",
        "          prob224=cv2.resize(hand_prob, (224,224), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "          \n",
        "                                                                          \n",
        "  #before we track the histogram, we first need to detect the face and get the position\n",
        "\n",
        "    else:\n",
        "\n",
        "    \n",
        "          gray = cv2.cvtColor(vis, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "          #use Cascade classifier to detect the face\n",
        "\n",
        "          rects = detect(gray, cascade)\n",
        "\n",
        "          if len(rects)>0:\n",
        "\n",
        "            for rect in rects:\n",
        "              x11,y11,x22,y22=rect\n",
        "\n",
        "            track_window=(x11,y11,x22-x11,y22-y11)\n",
        "            hsv_roi = hsv[y11:y22,x11:x22]\n",
        "            mask_roi = mask[y11:y22,x11:x22]\n",
        "\n",
        "            #calculate the histogram\n",
        "            hist = cv2.calcHist( [hsv_roi], [0], mask_roi, [16], [0, 180] )\n",
        "            cv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX)\n",
        "            hist = hist.reshape(-1)\n",
        "            vis_roi =vis[y11:y22,x11:x22]\n",
        "            cv2.bitwise_not(vis_roi, vis_roi)\n",
        "            vis[mask == 0] = 0\n",
        "\n",
        "            #set the margin as 20% of the height plus 30 pixels\n",
        "            pad=int(0.2*(y22-y11))+30\n",
        "            x1=x11-pad \n",
        "            # make sure the space lie inside the video screen\n",
        "            if x1 <0 :\n",
        "              x1=0\n",
        "\n",
        "            y1=y11-pad\n",
        "            if y1 <0:\n",
        "              y1=0\n",
        "\n",
        "            xx,yy,ww,hh=track_window\n",
        "            track_window=(xx-x1,yy-y1,ww,hh)\n",
        "\n",
        "            #for subrects in rects:\n",
        "              #draw_rects(imcopy, subrects, (0, 255, 0))   \n",
        "\n",
        "    eval_js('showimg(\"{}\")'.format(image2byte(imcopy)))\n",
        "\n",
        "\n",
        "\n",
        "    if len(prob16)>0:\n",
        "\n",
        "      #we save the 224*224 probability matrix\n",
        "\n",
        "      filename224=\"test_\"+str(224)+\"_test\"+\".jpg\"\n",
        "\n",
        "      im2 = Image.fromarray(prob224)\n",
        "      im2.save(filename224)\n",
        "      hand_im=np.array(prob16)\n",
        "      hand_im=hand_im.flatten()\n",
        "      hand_im=hand_im.reshape(1,256)\n",
        "      prediction = loaded_model.predict(hand_im) # where hand_image is the probability image of your hand of size (1,256)\n",
        "      prediction = prediction.argmax()\n",
        "      predicted_letter = chr(ord('A') + prediction)\n",
        "\n",
        "      #this is for printing the current letter\n",
        "\n",
        "      sys.stdout.write(\"\\r\" + predicted_letter)\n",
        "      sys.stdout.flush()\n",
        "      \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNx-S4abMXV7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "outputId": "f6ee927f-5eda-4ad4-b413-bebdb271d270"
      },
      "source": [
        "#run this and show the gesture, it will print the letter above the video\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function create(){\n",
              "      div = document.createElement('div');\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      video = document.createElement('video');\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.style.display = \"none\";\n",
              "\n",
              "      div.appendChild(video);\n",
              "\n",
              "      stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: \"environment\"}});\n",
              "      video.srcObject = stream;\n",
              "\n",
              "      await video.play();\n",
              "\n",
              "      canvas =  document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "\n",
              "      div_out = document.createElement('div');\n",
              "      document.body.appendChild(div_out);\n",
              "      \n",
              "      img224 = document.createElement('img');\n",
              "      img224.id = \"finalImage224\";\n",
              "      div_out.appendChild(img224);\n",
              "\n",
              "      img64 = document.createElement('img');\n",
              "      img64.id = \"finalImage64\";\n",
              "      div_out.appendChild(img64);\n",
              "\n",
              "      transfer = document.createElement('div');\n",
              "      transfer.id = \"transfer\";\n",
              "      transfer.style.color = \"none\";\n",
              "      document.body.appendChild(transfer);\n",
              "\n",
              "      //window.arr64 = [];\n",
              "      //window.arr224 = [];\n",
              "\n",
              "    }\n",
              "\n",
              "    async function capture(){\n",
              "        return await new Promise(function(resolve, reject){\n",
              "            pendingResolve = resolve;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            result = canvas.toDataURL('image/jpeg', 0.8);\n",
              "            pendingResolve(result);\n",
              "        })\n",
              "    }\n",
              "\n",
              "    function showimg(imgsourceb64){\n",
              "        img64.src = \"data:image/jpg;base64,\" + imgsourceb64;\n",
              "    \n",
              "    }\n",
              "\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "C"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-fbd55f77ab7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-119-b052fd97f74e>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mbyte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'capture()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbyte2image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCuA8IXEMpvp"
      },
      "source": [
        "# Nineth Task: Using VGG\n",
        "first we import the vgg related packages we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAMHO4UXD84y"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.preprocessing import image as kimage\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQOog5G9Ergb"
      },
      "source": [
        "#get our 224*224 files\n",
        "path_to_images = \"/content/drive/My Drive/yourhand\"\n",
        "paths_list = sorted(glob.glob(path_to_images + \"/*_224.jpg\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KprZgESaNGg1"
      },
      "source": [
        "here we use the vgg model to extract fectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou9LLtW_EV7j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46552e32-79d3-4b46-f353-9cf9f7c88cd3"
      },
      "source": [
        "\n",
        "X = np.empty((len(paths_list), 224, 224, 3))\n",
        "for i, image_path in enumerate(paths_list):\n",
        "    image = kimage.load_img(image_path)\n",
        "    image = kimage.img_to_array(image)\n",
        "    image = preprocess_input(image) #will convert the images from RGB to BGR, then will zero-center each color channel with respect to the ImageNet dataset, without scaling.\n",
        "    X[i] = image\n",
        "\n",
        "vgg_model = VGG19(weights='imagenet') # Load VGG model and weights\n",
        "\n",
        "model_vgg = Model(inputs=vgg_model.input, outputs=[vgg_model.get_layer(\"fc2\").output]) # Get the fc2 layer instead of the prediction layer trained for ImageNet\n",
        "model_vgg.summary() # See our model\n",
        "\n",
        "output_feats = model_vgg.predict(X) # Extract features of our images. Size = (nb_images, 4096)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 35s 0us/step\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 139,570,240\n",
            "Trainable params: 139,570,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KcWMP7gJ0-z"
      },
      "source": [
        "#the output doesn't contain the letter so we put the letter back\n",
        "#create the list of letter\n",
        "letterlist=[]\n",
        "for path in paths_list:\n",
        "  letterlist.append(path.split(\"/\")[-1][0])\n",
        "#combine the letters with the output\n",
        "vggfile=np.concatenate((letterarray,output_feats ),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjSQIEsqISS_"
      },
      "source": [
        " #saving the txt file \n",
        "  with open('vgg.txt', 'w') as f:\n",
        "      np.savetxt(f, vggfile,delimiter=\",\", fmt='%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCrBehluz309"
      },
      "source": [
        "#shuffle the lines\n",
        "import random\n",
        "lines = open('vgg.txt').readlines()\n",
        "random.shuffle(lines)\n",
        "open('vgg.txt', 'w').writelines(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlubi9x2NzYE"
      },
      "source": [
        "Time to use this VGG model\n",
        "\n",
        "\n",
        "We did everything like before, build the keras model and then train it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyN_8_hLOdPw"
      },
      "source": [
        "#create dataset with lable\n",
        "samples_v, letters_v= load_dataset(\"vgg.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfVmiOTYQFWm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "64b41ac6-c29f-4afd-d8fa-67dcf9d92dfc"
      },
      "source": [
        "#split the dataset\n",
        "num_classes=4\n",
        "#because the dataset is too small, I set the ratio as 0.8 for using more training data\n",
        "train_ratio = 0.8\n",
        "n_train_samples_v = int(len(samples_v) * train_ratio)\n",
        "x_train_v, y_train_v = samples_v[:n_train_samples_v], letters_v[:n_train_samples_v]\n",
        "x_val_v, y_val_v = samples_v[n_train_samples_v:], letters_v[n_train_samples_v:]\n",
        "\n",
        "x_train_v = x_train_v.astype('float32')\n",
        "x_val_v = x_val_v.astype('float32')\n",
        "\n",
        "print(x_train_v.shape[0], 'train samples')\n",
        "print(x_val_v.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train_v = keras.utils.to_categorical(y_train_v, num_classes)\n",
        "y_val_v = keras.utils.to_categorical(y_val_v, num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "582 train samples\n",
            "146 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZTF8XPTVwSD"
      },
      "source": [
        "#clear the previouss model built before building a new training model\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cwCMtthRpsX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "e445e08e-5276-4370-f7fa-e253a12f8b4e"
      },
      "source": [
        "# MLP\n",
        "epochs = 20\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1000, activation='relu', input_shape=(4096,)))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_v, y_train_v,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_val_v, y_val_v))\n",
        "score = model.evaluate(x_val_v, y_val_v, verbose=0)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 4004      \n",
            "=================================================================\n",
            "Total params: 4,101,004\n",
            "Trainable params: 4,101,004\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 582 samples, validate on 146 samples\n",
            "Epoch 1/20\n",
            "582/582 [==============================] - 1s 986us/step - loss: 6.3418 - accuracy: 0.6460 - val_loss: 2.6764 - val_accuracy: 0.6644\n",
            "Epoch 2/20\n",
            "582/582 [==============================] - 0s 828us/step - loss: 0.7446 - accuracy: 0.8677 - val_loss: 1.4026 - val_accuracy: 0.8151\n",
            "Epoch 3/20\n",
            "582/582 [==============================] - 0s 844us/step - loss: 0.9282 - accuracy: 0.8660 - val_loss: 5.3544 - val_accuracy: 0.4521\n",
            "Epoch 4/20\n",
            "582/582 [==============================] - 0s 819us/step - loss: 0.7315 - accuracy: 0.8900 - val_loss: 0.5028 - val_accuracy: 0.8904\n",
            "Epoch 5/20\n",
            "582/582 [==============================] - 0s 833us/step - loss: 0.2489 - accuracy: 0.9519 - val_loss: 0.4796 - val_accuracy: 0.9041\n",
            "Epoch 6/20\n",
            "582/582 [==============================] - 0s 852us/step - loss: 0.6910 - accuracy: 0.9278 - val_loss: 1.6510 - val_accuracy: 0.8151\n",
            "Epoch 7/20\n",
            "582/582 [==============================] - 0s 838us/step - loss: 0.1879 - accuracy: 0.9759 - val_loss: 0.1940 - val_accuracy: 0.9658\n",
            "Epoch 8/20\n",
            "582/582 [==============================] - 0s 841us/step - loss: 0.5389 - accuracy: 0.9519 - val_loss: 0.2798 - val_accuracy: 0.9384\n",
            "Epoch 9/20\n",
            "582/582 [==============================] - 0s 846us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9521\n",
            "Epoch 10/20\n",
            "582/582 [==============================] - 0s 823us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0312 - val_accuracy: 0.8356\n",
            "Epoch 11/20\n",
            "582/582 [==============================] - 0s 832us/step - loss: 0.6194 - accuracy: 0.9244 - val_loss: 0.2238 - val_accuracy: 0.9589\n",
            "Epoch 12/20\n",
            "582/582 [==============================] - 0s 850us/step - loss: 6.3572e-04 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9521\n",
            "Epoch 13/20\n",
            "582/582 [==============================] - 0s 848us/step - loss: 2.7459e-04 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9589\n",
            "Epoch 14/20\n",
            "582/582 [==============================] - 0s 847us/step - loss: 3.2313e-04 - accuracy: 1.0000 - val_loss: 0.8151 - val_accuracy: 0.8767\n",
            "Epoch 15/20\n",
            "582/582 [==============================] - 0s 842us/step - loss: 1.0086 - accuracy: 0.9158 - val_loss: 0.2365 - val_accuracy: 0.9521\n",
            "Epoch 16/20\n",
            "582/582 [==============================] - 0s 846us/step - loss: 2.0881e-04 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9589\n",
            "Epoch 17/20\n",
            "582/582 [==============================] - 0s 841us/step - loss: 1.5377e-04 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.9110\n",
            "Epoch 18/20\n",
            "582/582 [==============================] - 0s 836us/step - loss: 0.6701 - accuracy: 0.9347 - val_loss: 0.3646 - val_accuracy: 0.9247\n",
            "Epoch 19/20\n",
            "582/582 [==============================] - 1s 863us/step - loss: 0.0023 - accuracy: 0.9983 - val_loss: 0.2394 - val_accuracy: 0.9521\n",
            "Epoch 20/20\n",
            "582/582 [==============================] - 0s 841us/step - loss: 3.3084e-04 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9795\n",
            "Validation loss: 0.20637316960994512\n",
            "Validation accuracy: 0.9794520735740662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC8SEnwcTNUG"
      },
      "source": [
        "Epoch 10  Dense 300   Dropout 0.2  Dense 100    \\\\\\ Result:  loss: 0.1412 - accuracy: 0.9536 - val_loss: 0.3083 - val_accuracy: 0.9247\n",
        "\n",
        "Epoch 20  Dense 300  Dense 100   \\\\\\  Result: loss: 2.1775e-04 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9589\n",
        "\n",
        "Epoch 20  Dense 300     \\\\\\  Result: oss: 1.5439e-04 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9589\n",
        "\n",
        "Epoch 20  Dense 1000     \\\\\\  Result: loss: 3.3084e-04 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9795\n",
        "\n",
        "\n",
        "\n",
        "Epoch 20  Dense 1000  Dense 200   \\\\\\  Result: loss: 0.2312 - accuracy: 0.9639 - val_loss: 0.3055 - val_accuracy: 0.9521\n",
        "\n",
        "Epoch 20  Dense 1000  Dense 200 Dense 100 \\\\\\  Result: loss: 1.8428e-06 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9658\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlPUWIfdRL-s"
      },
      "source": [
        "The result 0.9795 is better than the one we got without vgg.(0.958)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z842c2sw6Tec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8837de5c-921e-4f2d-9733-2a7d3d687839"
      },
      "source": [
        "#save the model\n",
        "model_json_vgg = model.to_json()\n",
        "with open(\"model_vgg.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json_vgg)\n",
        "model.save_weights(\"model_weights_vgg.h5\")\n",
        "print(\"Saved vgg.model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved vgg.model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBgfnEP_6q5X"
      },
      "source": [
        "#read model\n",
        "from keras.models import model_from_json\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('model_vgg.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_weights_vgg.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C36qNU3966Z-"
      },
      "source": [
        "#this function is almost the same as the previous function for detecting without vgg\n",
        "def  vgg_test():\n",
        "  VideoCapture()\n",
        "  eval_js('create()')\n",
        "  show_backproj=False\n",
        "  take=False\n",
        "  #Initialize rects\n",
        "  rects=[]\n",
        "  track_window_hand=()\n",
        "  prob16=[]\n",
        "  prob224=[]\n",
        "\n",
        "  while True:\n",
        "    byte = eval_js('capture()')\n",
        "    im = byte2image(byte)\n",
        "    vis = im.copy()\n",
        "    imcopy=im.copy()\n",
        "    # load input image in hsv mode:\n",
        "    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "    mask = cv2.inRange(hsv, np.array((25., 30., 30.)), np.array((180., 180., 204.)))\n",
        "\n",
        "    new_track_window=None\n",
        "\n",
        "    # check if there's face been detected\n",
        "  \n",
        "    if len(rects):\n",
        "  #locate the position of face and define an area\n",
        "        for rect in rects:\n",
        "          x11,y11,x22,y22=rect\n",
        "          #set the margin as 20% of the height plus 30 pixels\n",
        "          pad=int(0.2*(y22-y11))+30\n",
        "          x1=x11-pad \n",
        "          # the space should lie inside the video screen\n",
        "          if x1 <0 :\n",
        "            x1=0\n",
        "\n",
        "          y1=y11-pad\n",
        "          if y1 <0:\n",
        "            y1=0\n",
        "\n",
        "          x2=x22+pad\n",
        "          if x2>im.shape[1]:\n",
        "            x2=im.shape[1]\n",
        "\n",
        "          y2=y22+pad\n",
        "          if y2>im.shape[0]:\n",
        "            y2=im.shape[0]\n",
        "\n",
        "          #back projection records how well the pixels fit the pixels of a histogram \n",
        "          prob = cv2.calcBackProject([hsv], [0], hist, [0, 180], 1)\n",
        "          prob &= mask\n",
        "          term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
        "\n",
        "          track_box, track_window = cv2.CamShift(prob[y1:y2,x1:x2], track_window, term_crit)\n",
        "\n",
        "          if track_window is not None:\n",
        "\n",
        "            xx,yy,ww,hh=track_window\n",
        "\n",
        "            rect=[xx+x1,yy+y1,xx++x1+ww,yy+y1+hh]\n",
        "\n",
        "          #if can't find the face in that area we search for the whole screen\n",
        "          else:\n",
        "\n",
        "              xr1,yr1,xr2,yr2=rect\n",
        "              track_window=(xr1+x1,yr1+y2,xr2-xr1,yr2-yr1)\n",
        "              track_box, track_window = cv2.CamShift(prob, track_window, term_crit)\n",
        "\n",
        "              xx,yy,ww,hh=track_window\n",
        "              rect=[xx,yy,xx+ww,yy+hh]\n",
        "            \n",
        "        # set the probability of face as zero \n",
        "          xp1,yp1,xp2,yp2=rect\n",
        "          prob2=prob\n",
        "          prob2[yp1:yp2,xp1:xp2]=0\n",
        "\n",
        "          if show_backproj is True:  \n",
        "            imcopy[:] = prob2[...,np.newaxis]\n",
        "      \n",
        "          #use the histgram we already get to find the hand\n",
        "\n",
        "          track_box_hand, track_window_hand = cv2.CamShift(prob2, track_window, term_crit)\n",
        "          xx,yy,ww,hh=track_window_hand\n",
        "          rect_hand=[xx,yy,xx+ww,yy+hh]\n",
        "\n",
        "          draw_rects(imcopy, rect_hand, (0, 255, 0))   \n",
        "\n",
        "          #the position of the hand \n",
        "\n",
        "          hand_prob=prob2[yy:yy+hh,xx:xx+ww]\n",
        "\n",
        "          #prob16 is for storing the probability of 16*16 image\n",
        "          #prob224 is for storing the probability of 224*224 image\n",
        "\n",
        "          prob16=cv2.resize(hand_prob, (16,16), interpolation = cv2.INTER_AREA)\n",
        "          prob224=cv2.resize(hand_prob, (224,224), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "          \n",
        "                                                                          \n",
        "  #before we track the histogram, we first need to detect the face and get the position\n",
        "\n",
        "    else:\n",
        "    \n",
        "          gray = cv2.cvtColor(vis, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "          #use Cascade classifier to detect the face\n",
        "\n",
        "          rects = detect(gray, cascade)\n",
        "\n",
        "          if len(rects)>0:\n",
        "\n",
        "            for rect in rects:\n",
        "              x11,y11,x22,y22=rect\n",
        "\n",
        "            track_window=(x11,y11,x22-x11,y22-y11)\n",
        "            hsv_roi = hsv[y11:y22,x11:x22]\n",
        "            mask_roi = mask[y11:y22,x11:x22]\n",
        "\n",
        "            #calculate the histogram\n",
        "            hist = cv2.calcHist( [hsv_roi], [0], mask_roi, [16], [0, 180] )\n",
        "            cv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX)\n",
        "            hist = hist.reshape(-1)\n",
        "            vis_roi =vis[y11:y22,x11:x22]\n",
        "            cv2.bitwise_not(vis_roi, vis_roi)\n",
        "            vis[mask == 0] = 0\n",
        "\n",
        "            #set the margin as 20% of the height plus 30 pixels\n",
        "            pad=int(0.2*(y22-y11))+30\n",
        "            x1=x11-pad \n",
        "            # make sure the space lie inside the video screen\n",
        "            if x1 <0 :\n",
        "              x1=0\n",
        "\n",
        "            y1=y11-pad\n",
        "            if y1 <0:\n",
        "              y1=0\n",
        "\n",
        "            xx,yy,ww,hh=track_window\n",
        "            track_window=(xx-x1,yy-y1,ww,hh)\n",
        "\n",
        "            #for subrects in rects:\n",
        "              #draw_rects(imcopy, subrects, (0, 255, 0))   \n",
        "\n",
        "    eval_js('showimg(\"{}\")'.format(image2byte(imcopy)))\n",
        "\n",
        "\n",
        "\n",
        "    if len(prob16)>0:\n",
        "\n",
        "      filename224=\"test_\"+str(224)+\"_test\"+\".jpg\"\n",
        "     \n",
        "      im224 = Image.fromarray(prob224)\n",
        "      im224.save(filename224)\n",
        "      x=np.empty((1,224,224,3))\n",
        "      image = kimage.load_img(filename224)\n",
        "      image = kimage.img_to_array(image)\n",
        "      image = preprocess_input(image)\n",
        "      x[0]=image    \n",
        "      out=model_vgg.predict(x)  \n",
        "      #Following is using  MLP\n",
        "      prediction = loaded_model.predict(out) \n",
        "      prediction = prediction.argmax()\n",
        "      predicted_letter = chr(ord('A') + prediction)\n",
        "\n",
        "      #this is for printing the current letter\n",
        "\n",
        "      sys.stdout.write(\"\\r\" + predicted_letter)\n",
        "      sys.stdout.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfJ8AXM99B1T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "outputId": "2440bd01-2d8f-4347-fb7d-0e29b7713758"
      },
      "source": [
        "#test our vgg model, hope it works better\n",
        "vgg_test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function create(){\n",
              "      div = document.createElement('div');\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      video = document.createElement('video');\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.style.display = \"none\";\n",
              "\n",
              "      div.appendChild(video);\n",
              "\n",
              "      stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: \"environment\"}});\n",
              "      video.srcObject = stream;\n",
              "\n",
              "      await video.play();\n",
              "\n",
              "      canvas =  document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "\n",
              "      div_out = document.createElement('div');\n",
              "      document.body.appendChild(div_out);\n",
              "      \n",
              "      img224 = document.createElement('img');\n",
              "      img224.id = \"finalImage224\";\n",
              "      div_out.appendChild(img224);\n",
              "\n",
              "      img64 = document.createElement('img');\n",
              "      img64.id = \"finalImage64\";\n",
              "      div_out.appendChild(img64);\n",
              "\n",
              "      transfer = document.createElement('div');\n",
              "      transfer.id = \"transfer\";\n",
              "      transfer.style.color = \"none\";\n",
              "      document.body.appendChild(transfer);\n",
              "\n",
              "      //window.arr64 = [];\n",
              "      //window.arr224 = [];\n",
              "\n",
              "    }\n",
              "\n",
              "    async function capture(){\n",
              "        return await new Promise(function(resolve, reject){\n",
              "            pendingResolve = resolve;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            result = canvas.toDataURL('image/jpeg', 0.8);\n",
              "            pendingResolve(result);\n",
              "        })\n",
              "    }\n",
              "\n",
              "    function showimg(imgsourceb64){\n",
              "        img64.src = \"data:image/jpg;base64,\" + imgsourceb64;\n",
              "    \n",
              "    }\n",
              "\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "C"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-296-56acb40cdaeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-292-de6bc37eef6e>\u001b[0m in \u001b[0;36mvgg_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mbyte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'capture()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbyte2image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyV9IQm2Za8o"
      },
      "source": [
        "# Readme\n",
        "\n",
        "1.Run the code by order. When you run 'Create dataset' cell, every time you click the button, it will save two hand image. The two image probability are size 16* 16 and 224* 224 respectively. \n",
        "\n",
        "2.The probability files will be saved in Google drive. We also save all the 16*16 images into a txt file.\n",
        "\n",
        "3.Then we use the dataset to train, save and test the first model\n",
        "\n",
        "4.Build the vgg model and then train, save and test the second model\n",
        "\n",
        "Notice: The hand detection is sometimes affected by the noise in the background and light condition. It's better to find the suitable hsv before detecting.\n",
        "Even so, the result is still affected by the environment\n",
        "\n",
        "For the hand tracking code, the process is, it first detect the face, get the histgram of face, then use this histgram to find the hand."
      ]
    }
  ]
}